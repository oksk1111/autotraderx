"""
Ollama ê¸°ë°˜ AI íŠ¸ë ˆì´ë”© íŒë‹¨ ì—”ì§„
DeepSeek-R1 ëª¨ë¸ì„ í™œìš©í•œ ì‹¤ì‹œê°„ ë§¤ë§¤ ì˜ì‚¬ê²°ì •
"""
import requests
import logging
from typing import Dict, List, Optional
from app.core.config import settings

logger = logging.getLogger(__name__)


class OllamaEngine:
    """Ollama LLM ê¸°ë°˜ íŠ¸ë ˆì´ë”© AI ì—”ì§„"""
    
    def __init__(self):
        self.base_url = getattr(settings, 'OLLAMA_API_URL', 'http://localhost:11434')
        self.model = getattr(settings, 'OLLAMA_MODEL', 'deepseek-r1:8b')
        self.temperature = getattr(settings, 'OLLAMA_TEMPERATURE', 0.7)
        
    def get_available_models(self) -> List[Dict]:
        """Ollamaì— ì„¤ì¹˜ëœ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
        try:
            response = requests.get(
                f"{self.base_url}/api/tags",
                timeout=5
            )
            
            if response.status_code == 200:
                data = response.json()
                models = data.get('models', [])
                return [
                    {
                        'name': model.get('name'),
                        'size': model.get('size', 0),
                        'modified_at': model.get('modified_at'),
                        'digest': model.get('digest', '')[:12]  # ì§§ê²Œ í‘œì‹œ
                    }
                    for model in models
                ]
            else:
                logger.error(f"Failed to get models: {response.status_code}")
                return []
                
        except Exception as e:
            logger.error(f"Error getting models: {e}")
            return []
    
    def set_model(self, model_name: str) -> bool:
        """ì‚¬ìš©í•  ëª¨ë¸ ë³€ê²½"""
        try:
            # ëª¨ë¸ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            available_models = self.get_available_models()
            model_names = [m['name'] for m in available_models]
            
            if model_name not in model_names:
                logger.error(f"Model {model_name} not found. Available: {model_names}")
                return False
            
            self.model = model_name
            logger.info(f"Model changed to: {model_name}")
            return True
            
        except Exception as e:
            logger.error(f"Error setting model: {e}")
            return False
    
    def pull_model(self, model_name: str) -> Dict:
        """Ollama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        try:
            logger.info(f"Pulling model: {model_name}")
            
            response = requests.post(
                f"{self.base_url}/api/pull",
                json={"name": model_name},
                timeout=600,  # 10ë¶„ íƒ€ì„ì•„ì›ƒ
                stream=True
            )
            
            if response.status_code == 200:
                # ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ ì²˜ë¦¬
                for line in response.iter_lines():
                    if line:
                        # ì§„í–‰ ìƒí™© ë¡œê¹…
                        logger.info(line.decode('utf-8'))
                
                return {"success": True, "message": f"Model {model_name} downloaded"}
            else:
                return {"success": False, "message": f"Failed to pull model: {response.status_code}"}
                
        except Exception as e:
            logger.error(f"Error pulling model: {e}")
            return {"success": False, "message": str(e)}
        
    def _call_ollama(self, prompt: str) -> Optional[str]:
        """Ollama API í˜¸ì¶œ"""
        try:
            logger.info(f"Calling Ollama API with model: {self.model}")
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "temperature": self.temperature
                },
                timeout=180  # 3ë¶„ìœ¼ë¡œ ì¦ê°€ (DeepSeek-R1 ëª¨ë¸ì€ ì¶”ë¡ ì´ ëŠë¦¼)
            )
            
            if response.status_code == 200:
                result = response.json()
                response_text = result.get('response', '').strip()
                logger.info(f"Ollama ì‘ë‹µ ë°›ìŒ: {len(response_text)} ê¸€ì")
                return response_text
            else:
                logger.error(f"Ollama API error: {response.status_code}, {response.text}")
                return None
                
        except requests.exceptions.ConnectionError as e:
            logger.error(f"Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return None
        except requests.exceptions.Timeout as e:
            logger.error(f"Ollama API íƒ€ì„ì•„ì›ƒ: {e}")
            return None
        except Exception as e:
            logger.error(f"Ollama API call failed: {e}")
            return None
    
    def generate_trading_prompt(
        self,
        market_data: Dict,
        indicators: Dict,
        news_summary: Optional[str] = None,
        trend_score: Optional[float] = None
    ) -> str:
        """íŠ¸ë ˆì´ë”© íŒë‹¨ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        current_price = market_data.get('trade_price', 0)
        volume_24h = market_data.get('acc_trade_volume_24h', 0)
        change_rate = market_data.get('signed_change_rate', 0) * 100
        
        rsi = indicators.get('rsi', 50)
        macd = indicators.get('macd', {})
        ma_5 = indicators.get('ma_5', 0)
        ma_20 = indicators.get('ma_20', 0)
        mfi = indicators.get('mfi', 50)
        trend = indicators.get('trend', 'neutral')
        
        prompt = f"""ë‹¹ì‹ ì€ ì•”í˜¸í™”í ë‹¨ê¸° íŠ¸ë ˆì´ë”© ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì‹œì¥ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë§¤ë§¤ ê²°ì •ì„ ë‚´ë ¤ì£¼ì„¸ìš”.

## ğŸ“Š í˜„ì¬ ì‹œì¥ ìƒí™©
- í˜„ì¬ê°€: {current_price:,.0f}ì›
- 24ì‹œê°„ ê±°ë˜ëŸ‰: {volume_24h:,.2f}
- ë“±ë½ë¥ : {change_rate:+.2f}%

## ğŸ“ˆ ê¸°ìˆ ì  ì§€í‘œ
- RSI: {rsi:.2f} (30 ì´í•˜: ê³¼ë§¤ë„, 70 ì´ìƒ: ê³¼ë§¤ìˆ˜)
- MACD: {macd.get('macd', 0):.2f}, Signal: {macd.get('signal', 0):.2f}, Histogram: {macd.get('histogram', 0):.2f}
- 5ì¼ ì´ë™í‰ê· : {ma_5:,.0f}ì›
- 20ì¼ ì´ë™í‰ê· : {ma_20:,.0f}ì›
- MFI (ìê¸ˆíë¦„): {mfi:.2f}
- ì¶”ì„¸: {trend}

"""
        
        if news_summary:
            prompt += f"""## ğŸ“° ìµœê·¼ ë‰´ìŠ¤ ìš”ì•½
{news_summary}

"""
        
        if trend_score:
            prompt += f"""## ğŸ”¥ ê²€ìƒ‰ íŠ¸ë Œë“œ ì ìˆ˜
{trend_score}/100 (ê´€ì‹¬ë„ ì§€í‘œ)

"""
        
        prompt += """## ğŸ¯ ë§¤ë§¤ íŒë‹¨ ê¸°ì¤€
1. **ì›Œë‡¨ë ì‹ ë‹¨ê¸° íŠ¸ë ˆì´ë”© ì›ì¹™**
   - ê¸‰ìƒìŠ¹ íŒ¨í„´ í¬ì°© ì‹œ ì§„ì…
   - íŒ¨í„´ ì´íƒˆ ì¦‰ì‹œ ë§¤ë„
   - ì†ì ˆ: -1.5%, ìµì ˆ: +2.5%

2. **ê¸°ìˆ ì  ë¶„ì„**
   - RSI + MACD ë™ì‹œ ê³ ë ¤
   - ê±°ë˜ëŸ‰ ê¸‰ì¦ ì—¬ë¶€
   - ì´ë™í‰ê· ì„  ë°°ì—´

3. **ë¦¬ìŠ¤í¬ ê´€ë¦¬**
   - ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ êµ¬ê°„ íšŒí”¼
   - ì¶”ì„¸ ì „í™˜ ì‹œê·¸ë„ ì¤‘ìš”ë„ ë†’ìŒ

## ğŸ“ ê²°ì • ì¶œë ¥ í˜•ì‹
ë‹¤ìŒ ì¤‘ **ì •í™•íˆ í•˜ë‚˜ë§Œ** ì„ íƒí•˜ì—¬ ì¶œë ¥í•˜ì„¸ìš”:
- ë§¤ìˆ˜ (ì´ìœ : êµ¬ì²´ì ì¸ ê·¼ê±°)
- ë§¤ë„ (ì´ìœ : êµ¬ì²´ì ì¸ ê·¼ê±°)
- ìœ ì§€ (ì´ìœ : êµ¬ì²´ì ì¸ ê·¼ê±°)

**ê²°ì •:**
"""
        
        return prompt
    
    def analyze_and_decide(
        self,
        market_data: Dict,
        indicators: Dict,
        news_summary: Optional[str] = None,
        trend_score: Optional[float] = None
    ) -> Dict:
        """AI ê¸°ë°˜ ë§¤ë§¤ ì˜ì‚¬ê²°ì •"""
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.generate_trading_prompt(
            market_data, indicators, news_summary, trend_score
        )
        
        # Ollama í˜¸ì¶œ
        response = self._call_ollama(prompt)
        
        if not response:
            logger.warning("Ollama ì‘ë‹µ ì—†ìŒ - ê¸°ë³¸ ì „ëµìœ¼ë¡œ í´ë°±")
            return self._fallback_decision(indicators)
        
        # ì‘ë‹µ íŒŒì‹±
        decision = self._parse_decision(response)
        
        logger.info(f"AI íŒë‹¨: {decision['action']} - {decision['reason']}")
        
        return decision
    
    def _parse_decision(self, response: str) -> Dict:
        """Ollama ì‘ë‹µ íŒŒì‹±"""
        response_lower = response.lower()
        
        # ë§¤ìˆ˜/ë§¤ë„/ìœ ì§€ í‚¤ì›Œë“œ ê²€ìƒ‰
        if 'ë§¤ìˆ˜' in response or 'buy' in response_lower:
            action = 'buy'
            confidence = 0.8
        elif 'ë§¤ë„' in response or 'sell' in response_lower:
            action = 'sell'
            confidence = 0.8
        else:
            action = 'hold'
            confidence = 0.6
        
        # ì´ìœ  ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ì‹)
        reason = response.replace('\n', ' ').strip()[:200]
        
        return {
            'action': action,
            'confidence': confidence,
            'reason': reason,
            'raw_response': response
        }
    
    def _fallback_decision(self, indicators: Dict) -> Dict:
        """Ollama ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì „ëµ"""
        rsi = indicators.get('rsi', 50)
        macd = indicators.get('macd', {})
        
        if rsi < 30 and macd.get('histogram', 0) > 0:
            return {
                'action': 'buy',
                'confidence': 0.6,
                'reason': 'Fallback: RSI oversold + MACD positive'
            }
        elif rsi > 70 and macd.get('histogram', 0) < 0:
            return {
                'action': 'sell',
                'confidence': 0.6,
                'reason': 'Fallback: RSI overbought + MACD negative'
            }
        else:
            return {
                'action': 'hold',
                'confidence': 0.5,
                'reason': 'Fallback: No clear signal'
            }
    
    def check_health(self) -> bool:
        """Ollama ì„œë²„ ìƒíƒœ í™•ì¸"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False


# Singleton instance
ollama_engine = OllamaEngine()
